{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMKmFYSnALgs",
        "outputId": "7286f83b-3a7a-4ad0-a81a-d2305f412bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting download for tokyo_xs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1XmDqZBdEURc9NdyL4WdgIQMth-v7h477\n",
            "From (redirected): https://drive.google.com/uc?id=1XmDqZBdEURc9NdyL4WdgIQMth-v7h477&confirm=t&uuid=e3d3c0f0-bfad-4be2-9e2b-127588dcb90f\n",
            "To: /content/data/tokyo_xs.zip\n",
            "100%|██████████| 141M/141M [00:06<00:00, 22.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting download for sf_xs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1uoex2BWD9pOyJmz5rtZez0kyQvgZP-B4\n",
            "From (redirected): https://drive.google.com/uc?id=1uoex2BWD9pOyJmz5rtZez0kyQvgZP-B4&confirm=t&uuid=fdac95dd-27a1-4b7d-a215-809be9efec38\n",
            "To: /content/data/sf_xs.zip\n",
            "100%|██████████| 1.03G/1.03G [00:09<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os  # Module for interacting with the operating system (e.g., file and directory manipulation)\n",
        "import gdown  # Third-party module to download files from Google Drive\n",
        "import shutil  # Module to perform high-level file operations like copying, archiving, and removing\n",
        "\n",
        "# Define the download URLs in a dictionary.\n",
        "# Each key in the dictionary represents a dataset, and the corresponding value is the Google Drive URL.\n",
        "download_links = {\n",
        "    \"tokyo_xs\": \"https://drive.google.com/file/d/1XmDqZBdEURc9NdyL4WdgIQMth-v7h477/view?usp=share_link\",\n",
        "    \"sf_xs\": \"https://drive.google.com/file/d/1uoex2BWD9pOyJmz5rtZez0kyQvgZP-B4/view?usp=share_link\"\n",
        "    #\"gsv_xs\": \"https://drive.google.com/file/d/1nz-QAYU6EOQiVnEnDyJ30QmMTWOxrMv_/view?usp=share_link\"\n",
        "}\n",
        "\n",
        "# Ensure the \"data\" directory exists.\n",
        "# If the directory does not exist, it will be created using os.makedirs().\n",
        "data_directory = \"data\"\n",
        "if not os.path.exists(data_directory):\n",
        "    os.makedirs(data_directory)  # Creates the directory if it doesn't exist\n",
        "\n",
        "# Iterate through each dataset in the download_links dictionary.\n",
        "# For each entry, the name is the dataset identifier (e.g., \"tokyo_xs\"), and the link is the Google Drive URL.\n",
        "for name, link in download_links.items():\n",
        "    print(f\"Starting download for {name}\")  # Print a message indicating the start of the download process\n",
        "\n",
        "    # Set the path where the downloaded zip file will be saved (e.g., \"data/tokyo_xs.zip\").\n",
        "    zip_path = os.path.join(data_directory, f\"{name}.zip\")\n",
        "\n",
        "    # Download the file from Google Drive using the gdown library.\n",
        "    # The 'fuzzy=True' argument allows gdown to handle file links in various formats.\n",
        "    gdown.download(link, zip_path, fuzzy=True)\n",
        "\n",
        "    # Extract the contents of the downloaded zip file into the data_directory.\n",
        "    # shutil.unpack_archive() automatically handles different archive formats (e.g., .zip, .tar).\n",
        "    shutil.unpack_archive(zip_path, extract_dir=data_directory)\n",
        "\n",
        "    # Once the zip file has been extracted, delete the original zip file to save space.\n",
        "    os.remove(zip_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htGZRQ6zRa2m",
        "outputId": "bc319e23-5a5e-4b44-f6b1-785cdb781f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'mldl2024'...\n",
            "remote: Enumerating objects: 11427, done.\u001b[K\n",
            "remote: Counting objects: 100% (1475/1475), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1276/1276), done.\u001b[K\n",
            "remote: Total 11427 (delta 110), reused 1469 (delta 106), pack-reused 9952 (from 1)\u001b[K\n",
            "Receiving objects: 100% (11427/11427), 1.32 GiB | 15.98 MiB/s, done.\n",
            "Resolving deltas: 100% (1219/1219), done.\n",
            "Updating files: 100% (9585/9585), done.\n"
          ]
        }
      ],
      "source": [
        "# change directory\n",
        "%cd /content\n",
        "# Clone repository\n",
        "!git clone https://github.com/Bertone-Fabio/mldl2024.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AObD3R-rgtK",
        "outputId": "3c6745a5-9eed-4be1-db62-293a9b1334f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (71.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->pytorch_lightning)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.7)\n",
            "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.11.6 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pytorch_lightning-2.4.0 torchmetrics-1.4.1\n",
            "Collecting pytorch_metric_learning\n",
            "  Downloading pytorch_metric_learning-2.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (1.3.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_metric_learning) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch_metric_learning) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->pytorch_metric_learning) (12.6.20)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch_metric_learning) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch_metric_learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch_metric_learning) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch_metric_learning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch_metric_learning) (1.3.0)\n",
            "Downloading pytorch_metric_learning-2.6.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytorch_metric_learning\n",
            "Successfully installed pytorch_metric_learning-2.6.0\n",
            "Collecting faiss-cpu==1.7.3\n",
            "  Downloading faiss_cpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Downloading faiss_cpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install pytorch_metric_learning\n",
        "!pip install faiss-cpu==1.7.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTv375mkqpgG",
        "outputId": "9ebf2aaf-93d1-4b1d-94ba-a016a5d51cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/mldl2024\n",
            "Collecting cudf-cu12@ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.4.1-cp310-cp310-manylinux_2_28_x86_64.whl#sha256=57366e7ef09dc63e0b389aff20df6c37d91e2790065861ee31a4720149f5b694 (from -r requirements.txt (line 59))\n",
            "  Using cached https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.4.1-cp310-cp310-manylinux_2_28_x86_64.whl (473.3 MB)\n",
            "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889 (from -r requirements.txt (line 87))\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hProcessing /colabtools/dist/google-colab-1.0.0.tar.gz (from -r requirements.txt (line 144))\n",
            "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/colabtools/dist/google-colab-1.0.0.tar.gz'\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# change directory\n",
        "%cd /content/mldl2024\n",
        "# install requirements\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dpdv7P79RfBE"
      },
      "outputs": [],
      "source": [
        "# Import utility functions from 'utils' (custom module).\n",
        "import utils\n",
        "\n",
        "# Import dataset classes for training and testing.\n",
        "from dataset.test_dataset import TestDataset\n",
        "from dataset.train_dataset import TrainDataset\n",
        "\n",
        "# PyTorch Lightning for simplifying training loops and multi-GPU training.\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# Core PyTorch library for tensor operations and neural networks.\n",
        "import torch\n",
        "\n",
        "# Checkpoint callback for saving model checkpoints during training.\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# Image transformations for preprocessing (e.g., resizing, normalizing).\n",
        "from torchvision import transforms as tfm\n",
        "\n",
        "# Pre-trained models for transfer learning from torchvision.\n",
        "import torchvision.models\n",
        "\n",
        "# Learning rate scheduler to adjust the learning rate during training.\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# Neural network module for defining layers, loss functions, etc.\n",
        "from torch import nn\n",
        "\n",
        "# Logging for tracking events and debugging.\n",
        "import logging\n",
        "\n",
        "# NumPy for array operations and numerical computations.\n",
        "import numpy as np\n",
        "\n",
        "# Datetime module for working with dates and timestamps.\n",
        "from datetime import datetime\n",
        "\n",
        "# ImageFolder for loading datasets organized in class-labeled folders.\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# DataLoader for batching and multi-threaded dataset loading.\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxeQl_TmUMYo"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3tlThnMjSQNL"
      },
      "outputs": [],
      "source": [
        "class VPRModel(pl.LightningModule):\n",
        "    \"\"\"This is the main model for Visual Place Recognition.\n",
        "    We use PyTorch Lightning for modularity purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                #---- Aggregator\n",
        "                agg_arch='avgpool',  # The architecture of the aggregator, default is 'avgpool'\n",
        "                agg_config={},  # Configuration dictionary for the aggregator\n",
        "\n",
        "                #---- Datasets\n",
        "                val_dataset=None,  # Validation dataset, can be None\n",
        "                test_dataset=None,  # Test dataset, can be None\n",
        "\n",
        "                #---- Train hyperparameters\n",
        "                lr=0.03,  # Learning rate for the optimizer\n",
        "                optimizer='sgd',  # Optimizer type, default is SGD\n",
        "                weight_decay=1e-3,  # Weight decay (L2 regularization)\n",
        "                momentum=0.9,  # Momentum factor for SGD\n",
        "                milestones=[5, 10, 15],  # Milestones for learning rate decay\n",
        "                T_max=10,  # Max number of iterations for Cosine Annealing LR (if used)\n",
        "                lr_mult=0.3,  # Learning rate multiplier for step LR scheduler\n",
        "\n",
        "                #----- Loss\n",
        "                loss_name='MultiSimilarityLoss',  # Name of the loss function\n",
        "                miner_name='MultiSimilarityMiner',  # Name of the miner (for online mining strategies)\n",
        "                miner_margin=0.1,  # Margin parameter for the miner\n",
        "                faiss_gpu=False,  # Flag to enable GPU acceleration with FAISS (for nearest neighbor search)\n",
        "\n",
        "                #--- Images to save\n",
        "                num_preds_to_save=0  # Number of predictions to save during evaluation\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.agg_arch = agg_arch  # Store aggregator architecture\n",
        "        self.agg_config = agg_config  # Store aggregator configuration\n",
        "\n",
        "        self.val_dataset = val_dataset  # Store validation dataset\n",
        "        self.test_dataset = test_dataset  # Store test dataset\n",
        "        self.test_name = self.get_test_name()  # Extract test name from the test dataset's directory\n",
        "\n",
        "        # Store training hyperparameters\n",
        "        self.lr = lr\n",
        "        self.optimizer = optimizer\n",
        "        self.weight_decay = weight_decay\n",
        "        self.momentum = momentum\n",
        "        self.milestones = milestones\n",
        "        self.lr_mult = lr_mult\n",
        "        self.T_max = T_max\n",
        "\n",
        "        # Store loss and miner parameters\n",
        "        self.loss_name = loss_name\n",
        "        self.miner_name = miner_name\n",
        "        self.miner_margin = miner_margin\n",
        "\n",
        "        self.save_hyperparameters()  # Write all hyperparameters into a file\n",
        "\n",
        "        # Initialize loss function and miner using utility functions\n",
        "        self.loss_fn = utils.get_loss(loss_name)\n",
        "        self.miner = utils.get_miner(miner_name, miner_margin)\n",
        "        self.batch_acc = []  # List to track the percentage of trivial pairs/triplets in each batch\n",
        "\n",
        "        self.faiss_gpu = faiss_gpu  # Set FAISS GPU flag\n",
        "\n",
        "        # Initialize lists to store outputs during validation and testing steps\n",
        "        self.validation_step_outputs = []\n",
        "        self.test_step_outputs = []\n",
        "\n",
        "        self.num_preds_to_save = num_preds_to_save  # Set the number of predictions to save\n",
        "        self.total_steps = 0  # Initialize total steps counter\n",
        "\n",
        "        # ----------------------------------\n",
        "        # Load the backbone and aggregator models\n",
        "        # Load the pretrained ResNet-18 model\n",
        "        pretrained_model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "        # Modify the backbone (cut at the third convolutional layer)\n",
        "        self.backbone = nn.Sequential(\n",
        "            pretrained_model.conv1,\n",
        "            pretrained_model.bn1,\n",
        "            pretrained_model.relu,\n",
        "            pretrained_model.maxpool,\n",
        "            pretrained_model.layer1,\n",
        "            pretrained_model.layer2,\n",
        "            pretrained_model.layer3,\n",
        "        )\n",
        "\n",
        "        # Load the aggregator model using the utility function\n",
        "        self.aggregator = utils.get_aggregator(agg_arch, agg_config)\n",
        "\n",
        "    # Define the forward pass for the model\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)  # Pass input through the backbone\n",
        "        x = self.aggregator(x)  # Pass output through the aggregator\n",
        "        return x  # Return the final output\n",
        "\n",
        "    # Configure the optimizer and learning rate scheduler\n",
        "    def configure_optimizers(self):\n",
        "        # Select the optimizer based on the provided name\n",
        "        if self.optimizer.lower() == 'sgd':\n",
        "            optimizer = torch.optim.SGD(self.parameters(),\n",
        "                                        lr=self.lr,\n",
        "                                        weight_decay=self.weight_decay,\n",
        "                                        momentum=self.momentum)\n",
        "        elif self.optimizer.lower() == 'adamw':\n",
        "            optimizer = torch.optim.AdamW(self.parameters(),\n",
        "                                          lr=self.lr,\n",
        "                                          weight_decay=self.weight_decay)\n",
        "        elif self.optimizer.lower() == 'adam':\n",
        "            optimizer = torch.optim.Adam(self.parameters(),\n",
        "                                         lr=self.lr,\n",
        "                                         weight_decay=self.weight_decay)\n",
        "        else:\n",
        "            raise ValueError(f'Optimizer {self.optimizer} has not been added to \"configure_optimizers()\"')\n",
        "\n",
        "        # Define a multi-step learning rate scheduler\n",
        "        scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=self.milestones, gamma=self.lr_mult)\n",
        "        #scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.T_max)\n",
        "        return [optimizer], [scheduler]  # Return the optimizer and scheduler as a list\n",
        "\n",
        "    # The loss function call (called at each training iteration)\n",
        "    def loss_function(self, descriptors, labels):\n",
        "        # If a miner is defined, use it to mine pairs/triplets\n",
        "        if self.miner is not None:\n",
        "            miner_outputs = self.miner(descriptors, labels)\n",
        "            loss = self.loss_fn(descriptors, labels, miner_outputs)\n",
        "\n",
        "            # Calculate the percentage of trivial pairs/triplets (those that do not contribute to the loss)\n",
        "            nb_samples = descriptors.shape[0]\n",
        "            nb_mined = len(set(miner_outputs[0].detach().cpu().numpy()))\n",
        "            batch_acc = 1.0 - (nb_mined / nb_samples)\n",
        "        else:\n",
        "            # If no miner is defined, calculate loss directly\n",
        "            loss = self.loss_fn(descriptors, labels)\n",
        "            batch_acc = 0.0\n",
        "            if isinstance(loss, tuple):\n",
        "                # Some losses perform online mining internally and return a tuple (loss, batch_accuracy)\n",
        "                loss, batch_acc = loss\n",
        "\n",
        "        # Store batch accuracy and reset at the start of each epoch\n",
        "        self.batch_acc.append(batch_acc)\n",
        "        # Log the average batch accuracy\n",
        "        self.log('b_acc', sum(self.batch_acc) / len(self.batch_acc), prog_bar=True, logger=True)\n",
        "        return loss  # Return the computed loss\n",
        "\n",
        "    # This is the training step executed at each iteration\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        places, labels = batch  # Unpack the batch into places and labels\n",
        "\n",
        "        # GSVCities yields places (each containing N images), so the dataloader returns a batch containing BS places\n",
        "        BS, N, ch, h, w = places.shape\n",
        "\n",
        "        # Reshape places and labels for processing\n",
        "        images = places.view(BS * N, ch, h, w)\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        # Feed forward the batch to the model\n",
        "        descriptors = self(images)  # Call the forward method defined above\n",
        "        loss = self.loss_function(descriptors, labels)  # Calculate the loss\n",
        "\n",
        "        # Increment the total steps counter\n",
        "        self.total_steps += 1\n",
        "        # Log the loss and total steps\n",
        "        self.log('loss', loss.item(), logger=True)\n",
        "        self.log('step', self.total_steps, logger=True)\n",
        "        return {'loss': loss}  # Return the loss in a dictionary\n",
        "\n",
        "    # This method is called at the end of each training epoch\n",
        "    def on_training_epoch_end(self, training_step_outputs):\n",
        "        # Reset the batch accuracy list for the next epoch\n",
        "        self.batch_acc = []\n",
        "\n",
        "    # The validation step, executed step by step over the validation set\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        places, _ = batch  # Unpack the batch (only places are needed)\n",
        "        # Calculate descriptors\n",
        "        descriptors = self(places)\n",
        "        # Store descriptors in the validation output list\n",
        "        self.validation_step_outputs.append(descriptors.detach().cpu())\n",
        "        return descriptors.detach().cpu()  # Return descriptors (detached from the computation graph)\n",
        "\n",
        "    # The test step, executed step by step over the test set\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        places, _ = batch  # Unpack the batch (only places are needed)\n",
        "        # Calculate descriptors\n",
        "        descriptors = self(places)\n",
        "        # Store descriptors in the test output list\n",
        "        self.test_step_outputs.append(descriptors.detach().cpu())\n",
        "        return descriptors.detach().cpu()  # Return descriptors (detached from the computation graph)\n",
        "\n",
        "    # This method is called at the end of each validation epoch\n",
        "    def on_validation_epoch_end(self):\n",
        "        # Concatenate all validation descriptors\n",
        "        all_descriptors = torch.cat(self.validation_step_outputs, dim=0)\n",
        "        # Clear the validation output list\n",
        "        self.validation_step_outputs.clear()\n",
        "        # Perform inference and return results\n",
        "        return self.inference_epoch_end(all_descriptors, self.val_dataset, 'val', self.num_preds_to_save)\n",
        "\n",
        "    # This method is called at the end of each test epoch\n",
        "    def on_test_epoch_end(self):\n",
        "        # Concatenate all test descriptors\n",
        "        all_descriptors = torch.cat(self.test_step_outputs, dim=0)\n",
        "        # Clear the test output list\n",
        "        self.test_step_outputs.clear()\n",
        "        # Perform inference and return results\n",
        "        return self.inference_epoch_end(all_descriptors, self.test_dataset, 'test', self.num_preds_to_save)\n",
        "\n",
        "    # Save the total step count in the checkpoint\n",
        "    def on_save_checkpoint(self, checkpoint):\n",
        "        checkpoint['total_steps'] = self.total_steps  # Save the total steps count\n",
        "\n",
        "    # Load the total step count from the checkpoint\n",
        "    def on_load_checkpoint(self, checkpoint):\n",
        "        self.total_steps = checkpoint.get('total_steps', 0)  # Load the total steps count (default to 0)\n",
        "\n",
        "    # Method to change the number of predictions to save\n",
        "    def change_pred_to_save(self, num_pred):\n",
        "        self.num_preds_to_save = num_pred  # Update the number of predictions to save\n",
        "\n",
        "    # Extract the test name from the test dataset's root directory\n",
        "    def get_test_name(self):\n",
        "        test_dir = self.test_dataset.root_dir\n",
        "        return test_dir.split(\"/\")[-2]\n",
        "\n",
        "    # Method to change the test dataset\n",
        "    def change_test_dataset(self, test_dataset):\n",
        "        self.test_dataset = test_dataset  # Update the test dataset\n",
        "        self.test_name = self.get_test_name()  # Update the test name\n",
        "\n",
        "    # Method to change the validation dataset\n",
        "    def change_val_dataset(self, val_dataset):\n",
        "        self.val_dataset = val_dataset  # Update the validation dataset\n",
        "\n",
        "    # Perform inference at the end of each epoch\n",
        "    def inference_epoch_end(self, all_descriptors, inference_dataset, split, num_preds_to_save=0):\n",
        "        \"\"\"\n",
        "        At the end of each validation epoch, descriptors are returned in their order\n",
        "        depending on how the validation dataset is implemented.\n",
        "        For this project, it is always references then queries.\n",
        "        For example, if we have n references and m queries, we will get\n",
        "        the descriptors for each val_dataset in a list as follows:\n",
        "        [R1, R2, ..., Rn, Q1, Q2, ..., Qm]\n",
        "        We then split it to references=[R1, R2, ..., Rn] and queries=[Q1, Q2, ..., Qm]\n",
        "        to calculate recall@K using the ground truth provided.\n",
        "        \"\"\"\n",
        "\n",
        "        # Split descriptors into queries and database descriptors\n",
        "        queries_descriptors = all_descriptors[inference_dataset.num_db_images:]\n",
        "        database_descriptors = all_descriptors[:inference_dataset.num_db_images]\n",
        "\n",
        "        # Set the directory to save images based on the current split\n",
        "        if split == 'val':\n",
        "            save_dir = f\"images/{aggregation_method}_{loss}_{optimizer}_{miner}/epoch{self.current_epoch + final_epoch - 5}/{split}\"\n",
        "        else:\n",
        "            save_dir = f\"images/{aggregation_method}_{loss}_{optimizer}_{miner}/epoch{self.current_epoch + final_epoch - 5}/{split}/{self.test_name}\"\n",
        "\n",
        "        # Calculate recall@K and save predictions\n",
        "        recalls_dict, predictions = utils.get_validation_recalls(\n",
        "                                                eval_dataset=inference_dataset,\n",
        "                                                db_desc=database_descriptors,\n",
        "                                                q_desc=queries_descriptors,\n",
        "                                                k_values=[1, 5],  # Recall@1 and Recall@5\n",
        "                                                save_dir=save_dir,\n",
        "                                                print_results=True,\n",
        "                                                faiss_gpu=self.faiss_gpu,\n",
        "                                                num_queries_to_save=num_preds_to_save\n",
        "                                                )\n",
        "\n",
        "        # Format the recall results into a string\n",
        "        recalls_str = \"\".join([f\"R@{k}: {rec:.2f} \" for k, rec in recalls_dict.items()])\n",
        "\n",
        "        # Log the recall results\n",
        "        logging.info(f\"Epoch[{self.current_epoch:02d}]): \" +\n",
        "                     f\"recalls: {recalls_str}\")\n",
        "\n",
        "        # Log Recall@1 and Recall@5 for the current split\n",
        "        self.log(f'{split}/R@1', recalls_dict[1], prog_bar=False, logger=True)\n",
        "        self.log(f'{split}/R@5', recalls_dict[5], prog_bar=False, logger=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw2iCDmDWPaJ"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "train_path = \"/content/data/gsv_xs/train\"\n",
        "img_per_place = 4\n",
        "min_img_per_place = 4\n",
        "val_path = \"/content/data/sf_xs/val\"\n",
        "test_path = \"/content/data/sf_xs/test\"\n",
        "batch_size = 64\n",
        "aggregation_method = \"MixVPR\"\n",
        "loss = 'ContrastiveLoss'\n",
        "optimizer = 'adamw'\n",
        "weight_decay = 0.0001\n",
        "miner = \"MultiSimilarityMiner\"\n",
        "T_max = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6zEfOoCW6R9"
      },
      "outputs": [],
      "source": [
        "# Training data augmentation using Torchvision's transforms\n",
        "train_transform = tfm.Compose([\n",
        "    tfm.RandAugment(num_ops=3),  # Apply RandAugment with 3 augmentation operations\n",
        "    tfm.ToTensor(),  # Convert images to tensor format\n",
        "    tfm.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize images with ImageNet mean and std\n",
        "])\n",
        "\n",
        "# Instantiate the training dataset with the specified transform\n",
        "train_dataset = TrainDataset(\n",
        "    root_dir=train_path,  # Path to the training data\n",
        "    images_per_place=img_per_place,  # Number of images per place to use\n",
        "    minimum_images_per_place=min_img_per_place,  # Minimum number of images per place required\n",
        "    transform=train_transform  # Apply the data augmentation/transformations\n",
        ")\n",
        "\n",
        "# Instantiate the validation and test datasets without transformations\n",
        "val_dataset = TestDataset(root_dir=val_path)  # Path to the validation data\n",
        "test_dataset = TestDataset(root_dir=test_path)  # Path to the test data\n",
        "\n",
        "# Create DataLoader for training, validation, and testing\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,  # Use the training dataset\n",
        "    batch_size=batch_size,  # Number of samples per batch\n",
        "    num_workers=2,  # Number of subprocesses for data loading\n",
        "    shuffle=True  # Shuffle the data at every epoch\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,  # Use the validation dataset\n",
        "    batch_size=batch_size,  # Number of samples per batch\n",
        "    num_workers=2,  # Number of subprocesses for data loading\n",
        "    shuffle=False  # Do not shuffle validation data\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,  # Use the test dataset\n",
        "    batch_size=batch_size,  # Number of samples per batch\n",
        "    num_workers=2,  # Number of subprocesses for data loading\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Instantiate the Visual Place Recognition (VPR) model\n",
        "model = VPRModel(\n",
        "    agg_arch=aggregation_method,  # Aggregation method passed as a variable\n",
        "    agg_config={'in_channels': 256,  # Configuration for the selected aggregator\n",
        "                'in_h': 14,\n",
        "                'in_w': 14,\n",
        "                'out_channels': 256,\n",
        "                'mix_depth': 4,\n",
        "                'mlp_ratio': 1,\n",
        "                'out_rows': 4},\n",
        "\n",
        "    # ---- Datasets -----\n",
        "    val_dataset=val_dataset,  # Pass the validation dataset\n",
        "    test_dataset=test_dataset,  # Pass the test dataset\n",
        "\n",
        "    #-----------------------------------\n",
        "    #---- Training hyperparameters -----\n",
        "    lr=0.0002,  # Learning rate (e.g., 0.03 for SGD)\n",
        "    optimizer=optimizer,  # Optimizer type (e.g., SGD, Adam, or AdamW)\n",
        "    weight_decay=weight_decay,  # Weight decay (e.g., 0.001 for SGD or 0.0 for Adam)\n",
        "    momentum=0.9,  # Momentum factor for SGD\n",
        "    milestones=[5, 10, 15, 25],  # Milestones for learning rate scheduler\n",
        "    T_max=T_max,  # Maximum number of iterations for Cosine Annealing LR\n",
        "    lr_mult=0.3,  # Learning rate multiplier for scheduler\n",
        "\n",
        "    #---------------------------------\n",
        "    #---- Training loss function -----\n",
        "    loss_name=loss,  # Loss function (e.g., ContrastiveLoss, TripletMarginLoss)\n",
        "    miner_name=miner,  # Miner for online mining (e.g., PairMarginMiner, MultiSimilarityMiner)\n",
        "    miner_margin=0.1,  # Margin parameter for the miner\n",
        "    faiss_gpu=False,  # Use FAISS with GPU acceleration (False by default)\n",
        "    num_preds_to_save=5  # Number of predictions to save during evaluation\n",
        ")\n",
        "\n",
        "# Create directories for logging and checkpoints with a meaningful name\n",
        "final_epoch = 5  # Set the number of final epochs\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # Generate a timestamp for directory names\n",
        "log_dir = f\"logs/{aggregation_method}_{loss}_{optimizer}_{miner}_weight_decay{weight_decay}/final_epoch{final_epoch}_{timestamp}\"\n",
        "checkpoint_dir = f\"checkpoints/{aggregation_method}_{loss}_{optimizer}_{miner}_weight_decay{weight_decay}/final_epoch{final_epoch}_{timestamp}\"\n",
        "\n",
        "# Setup model checkpointing using PyTorch Lightning\n",
        "# Save the best models according to Recall@1 on the validation set\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    dirpath=checkpoint_dir,  # Directory to save checkpoints\n",
        "    monitor='val/R@1',  # Metric to monitor for saving the best model\n",
        "    filename='epoch({epoch:02d})_step({step:04d})_R1[{val/R@1:.4f}]_R5[{val/R@5:.4f}]',  # Checkpoint filename format\n",
        "    auto_insert_metric_name=False,  # Prevent automatic insertion of metric name into the filename\n",
        "    save_weights_only=True,  # Save only the model weights (not the entire model)\n",
        "    save_top_k=1,  # Save only the best model (top-1)\n",
        "    save_last=True,  # Save the last model checkpoint\n",
        "    mode='max'  # Maximize the monitored metric (Recall@1)\n",
        ")\n",
        "\n",
        "# Instantiate a PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='gpu', devices=[0],  # Use GPU acceleration on device 0\n",
        "    default_root_dir=log_dir,  # Set the root directory for logs\n",
        "    num_sanity_val_steps=0,  # Number of sanity validation steps before training starts\n",
        "    precision=16,  # Use 16-bit precision to reduce memory usage and increase speed\n",
        "    max_epochs=5,  # Maximum number of training epochs\n",
        "    check_val_every_n_epoch=1,  # Run validation every epoch\n",
        "    callbacks=[checkpoint_cb],  # Add checkpointing callback (additional callbacks can be added)\n",
        "    reload_dataloaders_every_n_epochs=1,  # Reload dataloaders to shuffle data every epoch\n",
        "    log_every_n_steps=20,  # Log metrics every 20 steps\n",
        "    # fast_dev_run=True  # Uncomment for a quick development run (skips full training)\n",
        ")\n",
        "\n",
        "# Start training the model\n",
        "# Validate the model before training (optional)\n",
        "# trainer.validate(model=model, dataloaders=val_loader)  # Uncomment if you want to validate before training\n",
        "\n",
        "# Fit the model on the training data and validate it on the validation data\n",
        "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
        "\n",
        "# Test the model after training (optional)\n",
        "# trainer.test(model=model, dataloaders=test_loader)  # Uncomment to run testing after training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY5UatRjYBm-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set global Git configuration for the user email and name\n",
        "!git config --global user.email \"fabio.bertone1@gmail.com\"  # Set your email for Git commits\n",
        "!git config --global user.name \"Bertone-Fabio\"  # Set your Git username\n",
        "\n",
        "# Pull the latest changes from the remote repository to ensure your local repo is up to date\n",
        "!git pull\n",
        "\n",
        "# Add all changes in the working directory to the staging area\n",
        "!git add -A\n",
        "\n",
        "# Commit the changes with a message that includes the checkpoint directory\n",
        "!git commit -m f\"add {checkpoint_dir}\"\n",
        "\n",
        "# Personal Access Token (PAT) for GitHub authentication\n",
        "token = \"\"  # Insert your GitHub PAT here (avoid hardcoding tokens directly in the code)\n",
        "\n",
        "# Configure the remote URL to include the token for authentication\n",
        "repo_url = f\"https://{token}@github.com/Bertone-Fabio/mldl2024.git\"\n",
        "\n",
        "# Set the remote URL for the repository to use the new token-authenticated URL\n",
        "!git remote set-url origin {repo_url}\n",
        "\n",
        "# Push the committed changes to the 'main' branch of the remote repository\n",
        "!git push origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF7m8e8JYFWt"
      },
      "outputs": [],
      "source": [
        "# Data augmentation and preprocessing pipeline for training\n",
        "train_transform = tfm.Compose([\n",
        "    tfm.RandAugment(num_ops=3),  # Apply RandAugment with 3 operations for data augmentation\n",
        "    tfm.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    tfm.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize using ImageNet mean and std\n",
        "])\n",
        "\n",
        "# Initialize the training dataset with transformations\n",
        "train_dataset = TrainDataset(\n",
        "    root_dir=train_path,  # Path to the training data directory\n",
        "    images_per_place=img_per_place,  # Number of images per place\n",
        "    minimum_images_per_place=min_img_per_place,  # Minimum images per place required to include in the dataset\n",
        "    transform=train_transform  # Apply the defined transformations\n",
        ")\n",
        "\n",
        "# Initialize the validation and test datasets without transformations\n",
        "val_dataset = TestDataset(root_dir=val_path)  # Path to the validation data directory\n",
        "test_dataset = TestDataset(root_dir=test_path)  # Path to the test data directory\n",
        "\n",
        "# Create DataLoaders for training, validation, and testing\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,  # Training dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=True  # Shuffle the training data each epoch\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,  # Validation dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=False  # Do not shuffle validation data\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,  # Test dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Set the checkpoint path (update this path before every run)\n",
        "checkpoint_path = '/content/mldl2024/checkpoints/MixVPR_MultiSimilarityLoss_adamw_MultiSimilarityMiner_Cosine_annealing_T_max5/final_epoch5_20240709-163808/last.ckpt'\n",
        "\n",
        "# Load the model from the specified checkpoint\n",
        "model = VPRModel.load_from_checkpoint(checkpoint_path)\n",
        "\n",
        "# Create directories for logging and checkpoints using a meaningful name\n",
        "final_epoch = 10  # Define the final epoch number\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # Generate a timestamp for unique directory names\n",
        "log_dir = f\"logs/{aggregation_method}_{loss}_{optimizer}_{miner}_Cosine_annealing_T_max{T_max}/final_epoch{final_epoch}_{timestamp}\"\n",
        "checkpoint_dir = f\"checkpoints/{aggregation_method}_{loss}_{optimizer}_{miner}_Cosine_annealing_T_max{T_max}/final_epoch{final_epoch}_{timestamp}\"\n",
        "\n",
        "# Setup model checkpointing using PyTorch Lightning\n",
        "# Save the best models according to Recall@1 on the validation set\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    dirpath=checkpoint_dir,  # Directory to save checkpoints\n",
        "    monitor='val/R@1',  # Metric to monitor for saving the best model\n",
        "    filename='epoch({epoch:02d})_step({step:04d})_R1[{val/R@1:.4f}]_R5[{val/R@5:.4f}]',  # Checkpoint filename format\n",
        "    auto_insert_metric_name=False,  # Prevent automatic insertion of metric name into the filename\n",
        "    save_weights_only=True,  # Save only the model weights (not the entire model)\n",
        "    save_top_k=1,  # Save only the best model (top-1)\n",
        "    save_last=True,  # Save the last model checkpoint\n",
        "    mode='max',  # Maximize the monitored metric (Recall@1)\n",
        ")\n",
        "\n",
        "# Instantiate the PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='gpu', devices=[0],  # Use GPU acceleration on device 0\n",
        "    default_root_dir=log_dir,  # Set the root directory for logs\n",
        "    num_sanity_val_steps=0,  # Number of sanity validation steps before training starts\n",
        "    precision=16,  # Use 16-bit precision to reduce memory usage and increase speed\n",
        "    max_epochs=5,  # Maximum number of training epochs\n",
        "    check_val_every_n_epoch=1,  # Run validation every epoch\n",
        "    callbacks=[checkpoint_cb],  # Add checkpointing callback (additional callbacks can be added)\n",
        "    reload_dataloaders_every_n_epochs=1,  # Reload dataloaders to shuffle data every epoch\n",
        "    log_every_n_steps=20,  # Log metrics every 20 steps\n",
        "    # fast_dev_run=True  # Uncomment for a quick development run (skips full training)\n",
        ")\n",
        "\n",
        "# Optionally, validate the model before training (e.g., if loading from a checkpoint)\n",
        "# trainer.validate(model=model, dataloaders=val_loader)  # Uncomment to run validation before training\n",
        "\n",
        "# Train the model on the training data and validate on the validation data\n",
        "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
        "\n",
        "# Optionally, test the model after training using the test data\n",
        "# trainer.test(model=model, dataloaders=test_loader, ckpt_path='best')  # Uncomment to run testing after training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K61Ij6waKUA"
      },
      "source": [
        "# Test on San Francisco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779,
          "referenced_widgets": [
            "424cae4d718a43eb83d244de02843ce5",
            "b68936d0e54344d4b787e9b6ca75029a",
            "28783154c7714f049a86af8931fb4718",
            "8ff301f971bd44ec96eb41b08c75f595",
            "4d34c57561924cad8907e9f91dbaea87",
            "b2ecb051e8814fab837ba28e09ce204a",
            "8f20f2f0a54e47caa24271e916251202",
            "ef2ffa779313478fb7d0d8c494a798e6",
            "23ac49930ae34227a86cb504b34f69a5",
            "fac91d1335584eeeaa61d624ba7f5590",
            "e7eebbf9882840ef871ae53d79ffbfe7",
            "342dbc571e1c49e5833bf5197f172fbe",
            "edd7ae7904544bdfac09947faa7e50fb",
            "15c76e931afe46d89bacbd381cf3e63e",
            "bacca56d246c4421aecf1a4352cfbec6",
            "59216ac625124880b7a19bc11ce906bc",
            "c725f55f1ba74fb8bd10ed690d4453e9",
            "813401aa526b48b29e6cc4210293e408",
            "7918b116492547ae88c38e4e015da1cb",
            "727f22329848444fb135252775b73389",
            "285e41770d8a4b5a8a7fae4c0a9fec53",
            "6e4c5069c28a42ea92d669a96af36645"
          ]
        },
        "id": "WbhOYKW4Yuoq",
        "outputId": "69ea966d-179d-4b17-c35f-1c1ae51ffe12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "424cae4d718a43eb83d244de02843ce5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "+--------------------------+\n",
            "|   Performance on Name    |\n",
            "+----------+-------+-------+\n",
            "|    K     |   1   |   5   |\n",
            "+----------+-------+-------+\n",
            "| Recall@K | 56.94 | 71.14 |\n",
            "+----------+-------+-------+\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          val/R@1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5693731904029846     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          val/R@5          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.711372435092926     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m         val/R@1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5693731904029846    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m         val/R@5         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.711372435092926    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "342dbc571e1c49e5833bf5197f172fbe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "+--------------------------+\n",
            "|   Performance on Name    |\n",
            "+----------+-------+-------+\n",
            "|    K     |   1   |   5   |\n",
            "+----------+-------+-------+\n",
            "| Recall@K | 18.00 | 32.70 |\n",
            "+----------+-------+-------+\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/R@1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.18000000715255737    </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/R@5          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3269999921321869     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test/R@1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.18000000715255737   \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test/R@5         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3269999921321869    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test/R@1': 0.18000000715255737, 'test/R@5': 0.3269999921321869}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define dataset parameters\n",
        "train_path = \"/content/data/gsv_xs/train\"  # Path to the training dataset\n",
        "img_per_place = 4  # Number of images per place to be used in training\n",
        "min_img_per_place = 4  # Minimum number of images per place required to include in the dataset\n",
        "val_path = \"/content/data/sf_xs/val\"  # Path to the validation dataset\n",
        "test_path = \"/content/data/sf_xs/test\"  # Path to the test dataset\n",
        "batch_size = 64  # Number of samples per batch for training and evaluation\n",
        "\n",
        "# Define the data augmentation and preprocessing pipeline for the training data\n",
        "# train_transform = tfm.Compose([\n",
        "#     tfm.RandAugment(num_ops=3),  # Apply RandAugment with 3 operations for data augmentation\n",
        "#     tfm.ToTensor(),  # Convert images to PyTorch tensors\n",
        "#     tfm.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize using ImageNet mean and std\n",
        "# ])\n",
        "\n",
        "# Initialize the training dataset with transformations\n",
        "# train_dataset = TrainDataset(\n",
        "#     root_dir=train_path,  # Path to the training data directory\n",
        "#     images_per_place=img_per_place,  # Number of images per place\n",
        "#     minimum_images_per_place=min_img_per_place,  # Minimum images per place required to include in the dataset\n",
        "#     transform=train_transform  # Apply the defined transformations\n",
        "# )\n",
        "\n",
        "# Initialize the validation and test datasets without transformations\n",
        "val_dataset = TestDataset(root_dir=val_path)  # Path to the validation data directory\n",
        "test_dataset = TestDataset(root_dir=test_path)  # Path to the test data directory\n",
        "\n",
        "# Create DataLoaders for training, validation, and testing\n",
        "# train_loader = DataLoader(\n",
        "#     dataset=train_dataset,  # Training dataset\n",
        "#     batch_size=batch_size,  # Batch size\n",
        "#     num_workers=2,  # Number of workers for data loading\n",
        "#     shuffle=True  # Shuffle the training data each epoch\n",
        "# )\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,  # Validation dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=False  # Do not shuffle validation data\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,  # Test dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Set the checkpoint path (update this path before every run)\n",
        "checkpoint_path = '/content/mldl2024/checkpoints/avgpool_TripletMarginLoss_adam_None/final_epoch10_20240606-133724/last.ckpt'\n",
        "\n",
        "# Load the model from the specified checkpoint\n",
        "model = VPRModel.load_from_checkpoint(checkpoint_path)\n",
        "\n",
        "# Set the test dataset in the model to the newly loaded test dataset\n",
        "model.change_test_dataset(test_dataset)\n",
        "\n",
        "# Create directories for logging and checkpoints using a meaningful name\n",
        "final_epoch = 10  # Define the final epoch number\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # Generate a timestamp for unique directory names\n",
        "\n",
        "# Extract the directory name from the checkpoint path\n",
        "checkpoint_dir_name = checkpoint_path.split(\"/\")[-3]\n",
        "aggregation_method,loss,optimizer,miner = checkpoint_dir_name.split('_')\n",
        "\n",
        "# Create directories for logs and checkpoints based on the checkpoint name and timestamp\n",
        "log_dir = f\"logs/{checkpoint_dir_name}/test_{timestamp}_dataset_SF\"\n",
        "checkpoint_dir = f\"checkpoints/{checkpoint_dir_name}/test_{timestamp}_dataset_SF\"\n",
        "\n",
        "# Setup model checkpointing using PyTorch Lightning\n",
        "# Save the best models according to Recall@1 on the validation set\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    dirpath=checkpoint_dir,  # Directory to save checkpoints\n",
        "    monitor='val/R@1',  # Metric to monitor for saving the best model\n",
        "    filename='epoch({epoch:02d})_step({step:04d})_R1[{val/R@1:.4f}]_R5[{val/R@5:.4f}]',  # Checkpoint filename format\n",
        "    auto_insert_metric_name=False,  # Prevent automatic insertion of metric name into the filename\n",
        "    save_weights_only=True,  # Save only the model weights (not the entire model)\n",
        "    save_top_k=1,  # Save only the best model (top-1)\n",
        "    save_last=True,  # Save the last model checkpoint\n",
        "    mode='max',  # Maximize the monitored metric (Recall@1)\n",
        ")\n",
        "\n",
        "# Instantiate the PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='gpu', devices=[0],  # Use GPU acceleration on device 0\n",
        "    default_root_dir=log_dir,  # Set the root directory for logs\n",
        "    num_sanity_val_steps=0,  # Number of sanity validation steps before training starts\n",
        "    precision=16,  # Use 16-bit precision to reduce memory usage and increase speed\n",
        "    max_epochs=5,  # Maximum number of training epochs\n",
        "    check_val_every_n_epoch=1,  # Run validation every epoch\n",
        "    callbacks=[checkpoint_cb],  # Add checkpointing callback (additional callbacks can be added)\n",
        "    reload_dataloaders_every_n_epochs=1,  # Reload dataloaders to shuffle data every epoch\n",
        "    log_every_n_steps=20,  # Log metrics every 20 steps\n",
        "    # fast_dev_run=True  # Uncomment for a quick development run (skips full training)\n",
        ")\n",
        "\n",
        "# If the model's current epoch is 0, set the final epoch to 15\n",
        "if model.current_epoch == 0:\n",
        "    final_epoch = 15\n",
        "\n",
        "# Validate the model on the validation dataset\n",
        "trainer.validate(model=model, dataloaders=val_loader)\n",
        "\n",
        "# Test the model on the test dataset\n",
        "trainer.test(model=model, dataloaders=test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99sUbGkkaiCm"
      },
      "source": [
        "# Test on Tokyo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477,
          "referenced_widgets": [
            "d3b922b7ed62435aac5a58d15e530d63",
            "25c326d31b4b446c96860d4ff43cdc20",
            "be3a07ec12ef42088c476d9a210d46bc",
            "1a86cee10b804212bb63d889e2aa1ad2",
            "9f6c037c6e914a0698b5d6f7273ad485",
            "47b3eb61c6db473db20654a8414fca42",
            "ca3191cb73aa49e49484ef13d0a7afd7",
            "4153fc279fe541d8b5fd807e4a60213b",
            "d1327c264cf14a44a37e49cd37bf9bd9",
            "402ca6586c83455db3b30f063c2b9475",
            "1c864dbad5304d9db454db464c7b1dca"
          ]
        },
        "id": "L5yzh41jaPFr",
        "outputId": "9e303cf8-f7bf-4e2d-82be-0a4fdf35b416"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3b922b7ed62435aac5a58d15e530d63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "+--------------------------+\n",
            "|   Performance on Name    |\n",
            "+----------+-------+-------+\n",
            "|    K     |   1   |   5   |\n",
            "+----------+-------+-------+\n",
            "| Recall@K | 26.67 | 45.71 |\n",
            "+----------+-------+-------+\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/R@1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2666666805744171     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/R@5          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4571428596973419     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test/R@1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2666666805744171    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test/R@5         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4571428596973419    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[{'test/R@1': 0.2666666805744171, 'test/R@5': 0.4571428596973419}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define the path to the test dataset\n",
        "test_path = \"/content/data/tokyo_xs/test\"\n",
        "\n",
        "test_dataset = TestDataset(root_dir=test_path)  # Path to the test data directory\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,  # Test dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Set the test dataset in the model\n",
        "# This updates the model's internal state to use the specified test dataset\n",
        "model.change_test_dataset(test_dataset)\n",
        "\n",
        "# Define the final epoch number and generate a timestamp for directory naming\n",
        "final_epoch = 10  # Define the final epoch number for naming directories\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # Generate a timestamp for unique directory names\n",
        "\n",
        "# Create directories for logs and checkpoints based on the checkpoint name and timestamp\n",
        "log_dir = f\"logs/{checkpoint_dir_name}/test_{timestamp}_dataset_Tokyo\"  # Directory for logs\n",
        "checkpoint_dir = f\"checkpoints/{checkpoint_dir_name}/test_{timestamp}_dataset_Tokyo\"  # Directory for checkpoints\n",
        "\n",
        "# Set up model checkpointing using PyTorch Lightning\n",
        "# The model checkpoints will be saved based on the best Recall@1 score on the validation set\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    dirpath=checkpoint_dir,  # Directory to save checkpoints\n",
        "    monitor='val/R@1',  # Metric to monitor for saving the best model\n",
        "    filename='epoch({epoch:02d})_step({step:04d})_R1[{val/R@1:.4f}]_R5[{val/R@5:.4f}]',  # Checkpoint filename format\n",
        "    auto_insert_metric_name=False,  # Prevent automatic insertion of metric name into the filename\n",
        "    save_weights_only=True,  # Save only the model weights (not the entire model)\n",
        "    save_top_k=1,  # Save only the best model (top-1)\n",
        "    save_last=True,  # Save the last model checkpoint\n",
        "    mode='max',  # Maximize the monitored metric (Recall@1)\n",
        ")\n",
        "\n",
        "# Instantiate the PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='gpu', devices=[0],  # Use GPU acceleration on device 0\n",
        "    default_root_dir=log_dir,  # Set the root directory for logs\n",
        "    num_sanity_val_steps=0,  # Number of sanity validation steps before training starts\n",
        "    precision=16,  # Use 16-bit precision to reduce memory usage and increase speed\n",
        "    max_epochs=5,  # Maximum number of training epochs\n",
        "    check_val_every_n_epoch=1,  # Run validation every epoch\n",
        "    callbacks=[checkpoint_cb],  # Add checkpointing callback (additional callbacks can be added)\n",
        "    reload_dataloaders_every_n_epochs=1,  # Reload dataloaders to shuffle data every epoch\n",
        "    log_every_n_steps=20,  # Log metrics every 20 steps\n",
        "    # fast_dev_run=True  # Uncomment for a quick development run (skips full training)\n",
        ")\n",
        "\n",
        "# Adjust final epoch if the model is at the beginning of training\n",
        "if model.current_epoch == 0:\n",
        "    final_epoch = 15\n",
        "\n",
        "# Validate the model on the validation dataset\n",
        "#trainer.validate(model=model, dataloaders=val_loader)\n",
        "\n",
        "# Test the model on the test dataset\n",
        "trainer.test(model=model, dataloaders=test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DcV-RCR1a9L",
        "outputId": "92861c8a-ff43-4e45-951a-6584aa543330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already up to date.\n",
            "[main 2fb6c66] ftested avgpool_TripletMarginLoss_adam_None\n",
            " 129 files changed, 979080 insertions(+)\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_131/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_131/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_131/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_131/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_131/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_131/query_131.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_294/pred_0_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_294/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_294/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_294/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_294/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_294/query_294.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_391/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_391/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_391/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_391/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_391/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_391/query_391.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_579/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_579/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_579/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_579/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_579/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_579/query_579.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_899/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_899/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_899/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_899/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_899/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/sf_xs/query_899/query_899.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_113/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_113/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_113/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_113/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_113/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_113/query_113.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_141/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_141/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_141/pred_2_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_141/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_141/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_141/query_141.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_150/pred_0_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_150/pred_1_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_150/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_150/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_150/pred_4_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_150/query_150.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_210/pred_0_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_210/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_210/pred_2_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_210/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_210/pred_4_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_210/query_210.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_233/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_233/pred_1_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_233/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_233/pred_3_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_233/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_233/query_233.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_24/pred_0_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_24/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_24/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_24/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_24/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_24/query_24.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_260/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_260/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_260/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_260/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_260/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_260/query_260.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_294/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_294/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_294/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_294/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_294/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_294/query_294.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_38/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_38/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_38/pred_2_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_38/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_38/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_38/query_38.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_42/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_42/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_42/pred_2_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_42/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_42/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/test/tokyo_xs/query_42/query_42.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1254/pred_0_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1254/pred_1_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1254/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1254/pred_3_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1254/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1254/query_1254.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1315/pred_0_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1315/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1315/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1315/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1315/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_1315/query_1315.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_3187/pred_0_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_3187/pred_1_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_3187/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_3187/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_3187/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_3187/query_3187.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_5226/pred_0_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_5226/pred_1_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_5226/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_5226/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_5226/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_5226/query_5226.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_649/pred_0_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_649/pred_1_correct.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_649/pred_2_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_649/pred_3_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_649/pred_4_incorrect.jpg\n",
            " create mode 100644 images/avgpool_TripletMarginLoss_adam_None/epoch10/val/query_649/query_649.jpg\n",
            " create mode 100644 logs/avgpool_TripletMarginLoss_adam_None/test_20240826-085220_dataset_SF/lightning_logs/version_0/events.out.tfevents.1724662347.7ed3b0e68fd3.458.0\n",
            " create mode 100644 logs/avgpool_TripletMarginLoss_adam_None/test_20240826-085220_dataset_SF/lightning_logs/version_0/hparams.yaml\n",
            " create mode 100644 logs/avgpool_TripletMarginLoss_adam_None/test_20240826-085738_dataset_SF/lightning_logs/version_0/events.out.tfevents.1724662659.7ed3b0e68fd3.458.1\n",
            " create mode 100644 logs/avgpool_TripletMarginLoss_adam_None/test_20240826-085738_dataset_SF/lightning_logs/version_0/events.out.tfevents.1724662731.7ed3b0e68fd3.458.2\n",
            " create mode 100644 logs/avgpool_TripletMarginLoss_adam_None/test_20240826-085738_dataset_SF/lightning_logs/version_0/hparams.yaml\n",
            " create mode 100644 logs/avgpool_TripletMarginLoss_adam_None/test_20240826-090036_dataset_Tokyo/lightning_logs/version_0/events.out.tfevents.1724662836.7ed3b0e68fd3.458.3\n",
            " create mode 100644 logs/avgpool_TripletMarginLoss_adam_None/test_20240826-090036_dataset_Tokyo/lightning_logs/version_0/hparams.yaml\n",
            " create mode 100644 logs/avgpool_TripletMarginLoss_adam_None/test_20240826-090225_dataset_Tokyo/lightning_logs/version_0/events.out.tfevents.1724662945.7ed3b0e68fd3.458.4\n",
            " create mode 100644 logs/avgpool_TripletMarginLoss_adam_None/test_20240826-090225_dataset_Tokyo/lightning_logs/version_0/hparams.yaml\n",
            "Enumerating objects: 173, done.\n",
            "Counting objects: 100% (173/173), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (161/161), done.\n",
            "Writing objects: 100% (169/169), 3.38 MiB | 3.46 MiB/s, done.\n",
            "Total 169 (delta 8), reused 16 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (8/8), completed with 4 local objects.\u001b[K\n",
            "remote: \n",
            "remote: GitHub found 4 vulnerabilities on Bertone-Fabio/mldl2024's default branch (1 critical, 2 high, 1 moderate). To find out more, visit:\u001b[K\n",
            "remote:      https://github.com/Bertone-Fabio/mldl2024/security/dependabot\u001b[K\n",
            "remote: \n",
            "To https://github.com/Bertone-Fabio/mldl2024.git\n",
            "   2cf7e21..2fb6c66  main -> main\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Set global Git configuration for the user email and name\n",
        "!git config --global user.email \"fabio.bertone1@gmail.com\"  # Set your email for Git commits\n",
        "!git config --global user.name \"Bertone-Fabio\"  # Set your Git username\n",
        "\n",
        "# Pull the latest changes from the remote repository to ensure your local repo is up to date\n",
        "!git pull\n",
        "\n",
        "# Add all changes in the working directory to the staging area\n",
        "!git add -A\n",
        "\n",
        "# Commit the changes with a message that includes the checkpoint directory\n",
        "!git commit -m f\"tested {checkpoint_dir_name}\"\n",
        "\n",
        "# Personal Access Token (PAT) for GitHub authentication\n",
        "token = \"\"  # Insert your GitHub PAT here (avoid hardcoding tokens directly in the code)\n",
        "\n",
        "# Configure the remote URL to include the token for authentication\n",
        "repo_url = f\"https://{token}@github.com/Bertone-Fabio/mldl2024.git\"\n",
        "\n",
        "# Set the remote URL for the repository to use the new token-authenticated URL\n",
        "!git remote set-url origin {repo_url}\n",
        "\n",
        "# Push the committed changes to the 'main' branch of the remote repository\n",
        "!git push origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnyAXm6bbash"
      },
      "source": [
        "# Image visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j5LfpTgbcWR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_images(folder_path, images_per_block):\n",
        "    \"\"\"\n",
        "    Visualizes images from a given folder and its subfolders in blocks of a specified number.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The path to the folder containing the images.\n",
        "        images_per_block (int): The number of images to display in each block.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get a list of all image paths in the folder and its subfolders\n",
        "    image_paths = []\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_path = os.path.join(root, file)\n",
        "                image_paths.append(image_path)\n",
        "\n",
        "    # Sort the image paths alphabetically\n",
        "    image_paths.sort()\n",
        "\n",
        "    # Visualize images in blocks\n",
        "    num_blocks = len(image_paths) // images_per_block\n",
        "    if len(image_paths) % images_per_block != 0:\n",
        "        num_blocks += 1\n",
        "\n",
        "    for block_index in range(num_blocks):\n",
        "        start_index = block_index * images_per_block\n",
        "        end_index = min(start_index + images_per_block, len(image_paths))\n",
        "\n",
        "        block_images = []\n",
        "        for image_index in range(start_index, end_index):\n",
        "            image_path = image_paths[image_index]\n",
        "            image = plt.imread(image_path)\n",
        "            block_images.append(image)\n",
        "\n",
        "        # Display images in the block\n",
        "        fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15, 15))\n",
        "        for row_index in range(4):\n",
        "            for col_index in range(5):\n",
        "                image_index = row_index * 5 + col_index\n",
        "                if image_index < len(block_images):\n",
        "                    axes[row_index, col_index].imshow(block_images[image_index])\n",
        "                    axes[row_index, col_index].axis('off')\n",
        "                else:\n",
        "                    axes[row_index, col_index].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example usage\n",
        "image_folder = \"/content/mldl2024/images/avgpool_MultiSimilarityLoss_adam_None/epoch10/test/tokyo_xs\"  # Replace with your folder path\n",
        "images_per_block = 20\n",
        "\n",
        "visualize_images(image_folder, images_per_block)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15c76e931afe46d89bacbd381cf3e63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7918b116492547ae88c38e4e015da1cb",
            "max": 441,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_727f22329848444fb135252775b73389",
            "value": 441
          }
        },
        "1a86cee10b804212bb63d889e2aa1ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_402ca6586c83455db3b30f063c2b9475",
            "placeholder": "​",
            "style": "IPY_MODEL_1c864dbad5304d9db454db464c7b1dca",
            "value": " 205/205 [00:25&lt;00:00,  7.99it/s]"
          }
        },
        "1c864dbad5304d9db454db464c7b1dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23ac49930ae34227a86cb504b34f69a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25c326d31b4b446c96860d4ff43cdc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47b3eb61c6db473db20654a8414fca42",
            "placeholder": "​",
            "style": "IPY_MODEL_ca3191cb73aa49e49484ef13d0a7afd7",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "285e41770d8a4b5a8a7fae4c0a9fec53": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28783154c7714f049a86af8931fb4718": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef2ffa779313478fb7d0d8c494a798e6",
            "max": 251,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23ac49930ae34227a86cb504b34f69a5",
            "value": 251
          }
        },
        "342dbc571e1c49e5833bf5197f172fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edd7ae7904544bdfac09947faa7e50fb",
              "IPY_MODEL_15c76e931afe46d89bacbd381cf3e63e",
              "IPY_MODEL_bacca56d246c4421aecf1a4352cfbec6"
            ],
            "layout": "IPY_MODEL_59216ac625124880b7a19bc11ce906bc"
          }
        },
        "402ca6586c83455db3b30f063c2b9475": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4153fc279fe541d8b5fd807e4a60213b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "424cae4d718a43eb83d244de02843ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b68936d0e54344d4b787e9b6ca75029a",
              "IPY_MODEL_28783154c7714f049a86af8931fb4718",
              "IPY_MODEL_8ff301f971bd44ec96eb41b08c75f595"
            ],
            "layout": "IPY_MODEL_4d34c57561924cad8907e9f91dbaea87"
          }
        },
        "47b3eb61c6db473db20654a8414fca42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d34c57561924cad8907e9f91dbaea87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "59216ac625124880b7a19bc11ce906bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6e4c5069c28a42ea92d669a96af36645": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "727f22329848444fb135252775b73389": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7918b116492547ae88c38e4e015da1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813401aa526b48b29e6cc4210293e408": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f20f2f0a54e47caa24271e916251202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ff301f971bd44ec96eb41b08c75f595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fac91d1335584eeeaa61d624ba7f5590",
            "placeholder": "​",
            "style": "IPY_MODEL_e7eebbf9882840ef871ae53d79ffbfe7",
            "value": " 251/251 [00:34&lt;00:00,  7.25it/s]"
          }
        },
        "9f6c037c6e914a0698b5d6f7273ad485": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "b2ecb051e8814fab837ba28e09ce204a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b68936d0e54344d4b787e9b6ca75029a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2ecb051e8814fab837ba28e09ce204a",
            "placeholder": "​",
            "style": "IPY_MODEL_8f20f2f0a54e47caa24271e916251202",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "bacca56d246c4421aecf1a4352cfbec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_285e41770d8a4b5a8a7fae4c0a9fec53",
            "placeholder": "​",
            "style": "IPY_MODEL_6e4c5069c28a42ea92d669a96af36645",
            "value": " 441/441 [00:55&lt;00:00,  7.97it/s]"
          }
        },
        "be3a07ec12ef42088c476d9a210d46bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4153fc279fe541d8b5fd807e4a60213b",
            "max": 205,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1327c264cf14a44a37e49cd37bf9bd9",
            "value": 205
          }
        },
        "c725f55f1ba74fb8bd10ed690d4453e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3191cb73aa49e49484ef13d0a7afd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1327c264cf14a44a37e49cd37bf9bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3b922b7ed62435aac5a58d15e530d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25c326d31b4b446c96860d4ff43cdc20",
              "IPY_MODEL_be3a07ec12ef42088c476d9a210d46bc",
              "IPY_MODEL_1a86cee10b804212bb63d889e2aa1ad2"
            ],
            "layout": "IPY_MODEL_9f6c037c6e914a0698b5d6f7273ad485"
          }
        },
        "e7eebbf9882840ef871ae53d79ffbfe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edd7ae7904544bdfac09947faa7e50fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c725f55f1ba74fb8bd10ed690d4453e9",
            "placeholder": "​",
            "style": "IPY_MODEL_813401aa526b48b29e6cc4210293e408",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "ef2ffa779313478fb7d0d8c494a798e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac91d1335584eeeaa61d624ba7f5590": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
