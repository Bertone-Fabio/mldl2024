{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMKmFYSnALgs"
      },
      "outputs": [],
      "source": [
        "import os  # Module for interacting with the operating system (e.g., file and directory manipulation)\n",
        "import gdown  # Third-party module to download files from Google Drive\n",
        "import shutil  # Module to perform high-level file operations like copying, archiving, and removing\n",
        "\n",
        "# Define the download URLs in a dictionary.\n",
        "# Each key in the dictionary represents a dataset, and the corresponding value is the Google Drive URL.\n",
        "download_links = {\n",
        "    \"tokyo_xs\": \"https://drive.google.com/file/d/1XmDqZBdEURc9NdyL4WdgIQMth-v7h477/view?usp=share_link\",\n",
        "    \"sf_xs\": \"https://drive.google.com/file/d/1uoex2BWD9pOyJmz5rtZez0kyQvgZP-B4/view?usp=share_link\",\n",
        "    \"gsv_xs\": \"https://drive.google.com/file/d/1nz-QAYU6EOQiVnEnDyJ30QmMTWOxrMv_/view?usp=share_link\"\n",
        "}\n",
        "\n",
        "# Ensure the \"data\" directory exists.\n",
        "# If the directory does not exist, it will be created using os.makedirs().\n",
        "data_directory = \"data\"\n",
        "if not os.path.exists(data_directory):\n",
        "    os.makedirs(data_directory)  # Creates the directory if it doesn't exist\n",
        "\n",
        "# Iterate through each dataset in the download_links dictionary.\n",
        "# For each entry, the name is the dataset identifier (e.g., \"tokyo_xs\"), and the link is the Google Drive URL.\n",
        "for name, link in download_links.items():\n",
        "    print(f\"Starting download for {name}\")  # Print a message indicating the start of the download process\n",
        "\n",
        "    # Set the path where the downloaded zip file will be saved (e.g., \"data/tokyo_xs.zip\").\n",
        "    zip_path = os.path.join(data_directory, f\"{name}.zip\")\n",
        "\n",
        "    # Download the file from Google Drive using the gdown library.\n",
        "    # The 'fuzzy=True' argument allows gdown to handle file links in various formats.\n",
        "    gdown.download(link, zip_path, fuzzy=True)\n",
        "\n",
        "    # Extract the contents of the downloaded zip file into the data_directory.\n",
        "    # shutil.unpack_archive() automatically handles different archive formats (e.g., .zip, .tar).\n",
        "    shutil.unpack_archive(zip_path, extract_dir=data_directory)\n",
        "\n",
        "    # Once the zip file has been extracted, delete the original zip file to save space.\n",
        "    os.remove(zip_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change directory\n",
        "%cd /content\n",
        "# Clone repository\n",
        "!git clone https://github.com/Bertone-Fabio/mldl2024.git\n",
        "# change directory\n",
        "%cd /content/mldl2024\n",
        "# install requirements\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "htGZRQ6zRa2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import utility functions from 'utils' (custom module).\n",
        "import utils\n",
        "\n",
        "# Import dataset classes for training and testing.\n",
        "from dataset.test_dataset import TestDataset\n",
        "from dataset.train_dataset import TrainDataset\n",
        "\n",
        "# PyTorch Lightning for simplifying training loops and multi-GPU training.\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# Core PyTorch library for tensor operations and neural networks.\n",
        "import torch\n",
        "\n",
        "# Checkpoint callback for saving model checkpoints during training.\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# Image transformations for preprocessing (e.g., resizing, normalizing).\n",
        "from torchvision import transforms as tfm\n",
        "\n",
        "# Pre-trained models for transfer learning from torchvision.\n",
        "import torchvision.models\n",
        "\n",
        "# Learning rate scheduler to adjust the learning rate during training.\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# Neural network module for defining layers, loss functions, etc.\n",
        "from torch import nn\n",
        "\n",
        "# Logging for tracking events and debugging.\n",
        "import logging\n",
        "\n",
        "# NumPy for array operations and numerical computations.\n",
        "import numpy as np\n",
        "\n",
        "# Datetime module for working with dates and timestamps.\n",
        "from datetime import datetime\n",
        "\n",
        "# ImageFolder for loading datasets organized in class-labeled folders.\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# DataLoader for batching and multi-threaded dataset loading.\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "dpdv7P79RfBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "uxeQl_TmUMYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VPRModel(pl.LightningModule):\n",
        "    \"\"\"This is the main model for Visual Place Recognition.\n",
        "    We use PyTorch Lightning for modularity purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                #---- Aggregator\n",
        "                agg_arch='avgpool',  # The architecture of the aggregator, default is 'avgpool'\n",
        "                agg_config={},  # Configuration dictionary for the aggregator\n",
        "\n",
        "                #---- Datasets\n",
        "                val_dataset=None,  # Validation dataset, can be None\n",
        "                test_dataset=None,  # Test dataset, can be None\n",
        "\n",
        "                #---- Train hyperparameters\n",
        "                lr=0.03,  # Learning rate for the optimizer\n",
        "                optimizer='sgd',  # Optimizer type, default is SGD\n",
        "                weight_decay=1e-3,  # Weight decay (L2 regularization)\n",
        "                momentum=0.9,  # Momentum factor for SGD\n",
        "                milestones=[5, 10, 15],  # Milestones for learning rate decay\n",
        "                T_max=10,  # Max number of iterations for Cosine Annealing LR (if used)\n",
        "                lr_mult=0.3,  # Learning rate multiplier for step LR scheduler\n",
        "\n",
        "                #----- Loss\n",
        "                loss_name='MultiSimilarityLoss',  # Name of the loss function\n",
        "                miner_name='MultiSimilarityMiner',  # Name of the miner (for online mining strategies)\n",
        "                miner_margin=0.1,  # Margin parameter for the miner\n",
        "                faiss_gpu=False,  # Flag to enable GPU acceleration with FAISS (for nearest neighbor search)\n",
        "\n",
        "                #--- Images to save\n",
        "                num_preds_to_save=0  # Number of predictions to save during evaluation\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.agg_arch = agg_arch  # Store aggregator architecture\n",
        "        self.agg_config = agg_config  # Store aggregator configuration\n",
        "\n",
        "        self.val_dataset = val_dataset  # Store validation dataset\n",
        "        self.test_dataset = test_dataset  # Store test dataset\n",
        "        self.test_name = self.get_test_name()  # Extract test name from the test dataset's directory\n",
        "\n",
        "        # Store training hyperparameters\n",
        "        self.lr = lr\n",
        "        self.optimizer = optimizer\n",
        "        self.weight_decay = weight_decay\n",
        "        self.momentum = momentum\n",
        "        self.milestones = milestones\n",
        "        self.lr_mult = lr_mult\n",
        "        self.T_max = T_max\n",
        "\n",
        "        # Store loss and miner parameters\n",
        "        self.loss_name = loss_name\n",
        "        self.miner_name = miner_name\n",
        "        self.miner_margin = miner_margin\n",
        "\n",
        "        self.save_hyperparameters()  # Write all hyperparameters into a file\n",
        "\n",
        "        # Initialize loss function and miner using utility functions\n",
        "        self.loss_fn = utils.get_loss(loss_name)\n",
        "        self.miner = utils.get_miner(miner_name, miner_margin)\n",
        "        self.batch_acc = []  # List to track the percentage of trivial pairs/triplets in each batch\n",
        "\n",
        "        self.faiss_gpu = faiss_gpu  # Set FAISS GPU flag\n",
        "\n",
        "        # Initialize lists to store outputs during validation and testing steps\n",
        "        self.validation_step_outputs = []\n",
        "        self.test_step_outputs = []\n",
        "\n",
        "        self.num_preds_to_save = num_preds_to_save  # Set the number of predictions to save\n",
        "        self.total_steps = 0  # Initialize total steps counter\n",
        "\n",
        "        # ----------------------------------\n",
        "        # Load the backbone and aggregator models\n",
        "        # Load the pretrained ResNet-18 model\n",
        "        pretrained_model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "\n",
        "        # Modify the backbone (cut at the third convolutional layer)\n",
        "        self.backbone = nn.Sequential(\n",
        "            pretrained_model.conv1,\n",
        "            pretrained_model.bn1,\n",
        "            pretrained_model.relu,\n",
        "            pretrained_model.maxpool,\n",
        "            pretrained_model.layer1,\n",
        "            pretrained_model.layer2,\n",
        "            pretrained_model.layer3,\n",
        "        )\n",
        "\n",
        "        # Load the aggregator model using the utility function\n",
        "        self.aggregator = utils.get_aggregator(agg_arch, agg_config)\n",
        "\n",
        "    # Define the forward pass for the model\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)  # Pass input through the backbone\n",
        "        x = self.aggregator(x)  # Pass output through the aggregator\n",
        "        return x  # Return the final output\n",
        "\n",
        "    # Configure the optimizer and learning rate scheduler\n",
        "    def configure_optimizers(self):\n",
        "        # Select the optimizer based on the provided name\n",
        "        if self.optimizer.lower() == 'sgd':\n",
        "            optimizer = torch.optim.SGD(self.parameters(),\n",
        "                                        lr=self.lr,\n",
        "                                        weight_decay=self.weight_decay,\n",
        "                                        momentum=self.momentum)\n",
        "        elif self.optimizer.lower() == 'adamw':\n",
        "            optimizer = torch.optim.AdamW(self.parameters(),\n",
        "                                          lr=self.lr,\n",
        "                                          weight_decay=self.weight_decay)\n",
        "        elif self.optimizer.lower() == 'adam':\n",
        "            optimizer = torch.optim.Adam(self.parameters(),\n",
        "                                         lr=self.lr,\n",
        "                                         weight_decay=self.weight_decay)\n",
        "        else:\n",
        "            raise ValueError(f'Optimizer {self.optimizer} has not been added to \"configure_optimizers()\"')\n",
        "\n",
        "        # Define a multi-step learning rate scheduler\n",
        "        scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=self.milestones, gamma=self.lr_mult)\n",
        "        #scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.T_max)\n",
        "        return [optimizer], [scheduler]  # Return the optimizer and scheduler as a list\n",
        "\n",
        "    # The loss function call (called at each training iteration)\n",
        "    def loss_function(self, descriptors, labels):\n",
        "        # If a miner is defined, use it to mine pairs/triplets\n",
        "        if self.miner is not None:\n",
        "            miner_outputs = self.miner(descriptors, labels)\n",
        "            loss = self.loss_fn(descriptors, labels, miner_outputs)\n",
        "\n",
        "            # Calculate the percentage of trivial pairs/triplets (those that do not contribute to the loss)\n",
        "            nb_samples = descriptors.shape[0]\n",
        "            nb_mined = len(set(miner_outputs[0].detach().cpu().numpy()))\n",
        "            batch_acc = 1.0 - (nb_mined / nb_samples)\n",
        "        else:\n",
        "            # If no miner is defined, calculate loss directly\n",
        "            loss = self.loss_fn(descriptors, labels)\n",
        "            batch_acc = 0.0\n",
        "            if isinstance(loss, tuple):\n",
        "                # Some losses perform online mining internally and return a tuple (loss, batch_accuracy)\n",
        "                loss, batch_acc = loss\n",
        "\n",
        "        # Store batch accuracy and reset at the start of each epoch\n",
        "        self.batch_acc.append(batch_acc)\n",
        "        # Log the average batch accuracy\n",
        "        self.log('b_acc', sum(self.batch_acc) / len(self.batch_acc), prog_bar=True, logger=True)\n",
        "        return loss  # Return the computed loss\n",
        "\n",
        "    # This is the training step executed at each iteration\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        places, labels = batch  # Unpack the batch into places and labels\n",
        "\n",
        "        # GSVCities yields places (each containing N images), so the dataloader returns a batch containing BS places\n",
        "        BS, N, ch, h, w = places.shape\n",
        "\n",
        "        # Reshape places and labels for processing\n",
        "        images = places.view(BS * N, ch, h, w)\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        # Feed forward the batch to the model\n",
        "        descriptors = self(images)  # Call the forward method defined above\n",
        "        loss = self.loss_function(descriptors, labels)  # Calculate the loss\n",
        "\n",
        "        # Increment the total steps counter\n",
        "        self.total_steps += 1\n",
        "        # Log the loss and total steps\n",
        "        self.log('loss', loss.item(), logger=True)\n",
        "        self.log('step', self.total_steps, logger=True)\n",
        "        return {'loss': loss}  # Return the loss in a dictionary\n",
        "\n",
        "    # This method is called at the end of each training epoch\n",
        "    def on_training_epoch_end(self, training_step_outputs):\n",
        "        # Reset the batch accuracy list for the next epoch\n",
        "        self.batch_acc = []\n",
        "\n",
        "    # The validation step, executed step by step over the validation set\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        places, _ = batch  # Unpack the batch (only places are needed)\n",
        "        # Calculate descriptors\n",
        "        descriptors = self(places)\n",
        "        # Store descriptors in the validation output list\n",
        "        self.validation_step_outputs.append(descriptors.detach().cpu())\n",
        "        return descriptors.detach().cpu()  # Return descriptors (detached from the computation graph)\n",
        "\n",
        "    # The test step, executed step by step over the test set\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        places, _ = batch  # Unpack the batch (only places are needed)\n",
        "        # Calculate descriptors\n",
        "        descriptors = self(places)\n",
        "        # Store descriptors in the test output list\n",
        "        self.test_step_outputs.append(descriptors.detach().cpu())\n",
        "        return descriptors.detach().cpu()  # Return descriptors (detached from the computation graph)\n",
        "\n",
        "    # This method is called at the end of each validation epoch\n",
        "    def on_validation_epoch_end(self):\n",
        "        # Concatenate all validation descriptors\n",
        "        all_descriptors = torch.cat(self.validation_step_outputs, dim=0)\n",
        "        # Clear the validation output list\n",
        "        self.validation_step_outputs.clear()\n",
        "        # Perform inference and return results\n",
        "        return self.inference_epoch_end(all_descriptors, self.val_dataset, 'val', self.num_preds_to_save)\n",
        "\n",
        "    # This method is called at the end of each test epoch\n",
        "    def on_test_epoch_end(self):\n",
        "        # Concatenate all test descriptors\n",
        "        all_descriptors = torch.cat(self.test_step_outputs, dim=0)\n",
        "        # Clear the test output list\n",
        "        self.test_step_outputs.clear()\n",
        "        # Perform inference and return results\n",
        "        return self.inference_epoch_end(all_descriptors, self.test_dataset, 'test', self.num_preds_to_save)\n",
        "\n",
        "    # Save the total step count in the checkpoint\n",
        "    def on_save_checkpoint(self, checkpoint):\n",
        "        checkpoint['total_steps'] = self.total_steps  # Save the total steps count\n",
        "\n",
        "    # Load the total step count from the checkpoint\n",
        "    def on_load_checkpoint(self, checkpoint):\n",
        "        self.total_steps = checkpoint.get('total_steps', 0)  # Load the total steps count (default to 0)\n",
        "\n",
        "    # Method to change the number of predictions to save\n",
        "    def change_pred_to_save(self, num_pred):\n",
        "        self.num_preds_to_save = num_pred  # Update the number of predictions to save\n",
        "\n",
        "    # Extract the test name from the test dataset's root directory\n",
        "    def get_test_name(self):\n",
        "        test_dir = self.test_dataset.root_dir\n",
        "        return test_dir.split(\"/\")[-2]\n",
        "\n",
        "    # Method to change the test dataset\n",
        "    def change_test_dataset(self, test_dataset):\n",
        "        self.test_dataset = test_dataset  # Update the test dataset\n",
        "        self.test_name = self.get_test_name()  # Update the test name\n",
        "\n",
        "    # Method to change the validation dataset\n",
        "    def change_val_dataset(self, val_dataset):\n",
        "        self.val_dataset = val_dataset  # Update the validation dataset\n",
        "\n",
        "    # Perform inference at the end of each epoch\n",
        "    def inference_epoch_end(self, all_descriptors, inference_dataset, split, num_preds_to_save=0):\n",
        "        \"\"\"\n",
        "        At the end of each validation epoch, descriptors are returned in their order\n",
        "        depending on how the validation dataset is implemented.\n",
        "        For this project, it is always references then queries.\n",
        "        For example, if we have n references and m queries, we will get\n",
        "        the descriptors for each val_dataset in a list as follows:\n",
        "        [R1, R2, ..., Rn, Q1, Q2, ..., Qm]\n",
        "        We then split it to references=[R1, R2, ..., Rn] and queries=[Q1, Q2, ..., Qm]\n",
        "        to calculate recall@K using the ground truth provided.\n",
        "        \"\"\"\n",
        "\n",
        "        # Split descriptors into queries and database descriptors\n",
        "        queries_descriptors = all_descriptors[inference_dataset.num_db_images:]\n",
        "        database_descriptors = all_descriptors[:inference_dataset.num_db_images]\n",
        "\n",
        "        # Set the directory to save images based on the current split\n",
        "        if split == 'val':\n",
        "            save_dir = f\"images/{aggregation_method}_{loss}_{optimizer}_{miner}/epoch{self.current_epoch + final_epoch - 5}/{split}\"\n",
        "        else:\n",
        "            save_dir = f\"images/{aggregation_method}_{loss}_{optimizer}_{miner}/epoch{self.current_epoch + final_epoch - 5}/{split}/{self.test_name}\"\n",
        "\n",
        "        # Calculate recall@K and save predictions\n",
        "        recalls_dict, predictions = utils.get_validation_recalls(\n",
        "                                                eval_dataset=inference_dataset,\n",
        "                                                db_desc=database_descriptors,\n",
        "                                                q_desc=queries_descriptors,\n",
        "                                                k_values=[1, 5],  # Recall@1 and Recall@5\n",
        "                                                save_dir=save_dir,\n",
        "                                                print_results=True,\n",
        "                                                faiss_gpu=self.faiss_gpu,\n",
        "                                                num_queries_to_save=num_preds_to_save\n",
        "                                                )\n",
        "\n",
        "        # Format the recall results into a string\n",
        "        recalls_str = \"\".join([f\"R@{k}: {rec:.2f} \" for k, rec in recalls_dict.items()])\n",
        "\n",
        "        # Log the recall results\n",
        "        logging.info(f\"Epoch[{self.current_epoch:02d}]): \" +\n",
        "                     f\"recalls: {recalls_str}\")\n",
        "\n",
        "        # Log Recall@1 and Recall@5 for the current split\n",
        "        self.log(f'{split}/R@1', recalls_dict[1], prog_bar=False, logger=True)\n",
        "        self.log(f'{split}/R@5', recalls_dict[5], prog_bar=False, logger=True)\n"
      ],
      "metadata": {
        "id": "3tlThnMjSQNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "train_path = \"/content/data/gsv_xs/train\"\n",
        "img_per_place = 4\n",
        "min_img_per_place = 4\n",
        "val_path = \"/content/data/sf_xs/val\"\n",
        "test_path = \"/content/data/sf_xs/test\"\n",
        "batch_size = 64\n",
        "aggregation_method = \"MixVPR\"\n",
        "loss = 'ContrastiveLoss'\n",
        "optimizer = 'adamw'\n",
        "weight_decay = 0.0001\n",
        "miner = \"MultiSimilarityMiner\"\n",
        "T_max = 5"
      ],
      "metadata": {
        "id": "iw2iCDmDWPaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data augmentation using Torchvision's transforms\n",
        "train_transform = tfm.Compose([\n",
        "    tfm.RandAugment(num_ops=3),  # Apply RandAugment with 3 augmentation operations\n",
        "    tfm.ToTensor(),  # Convert images to tensor format\n",
        "    tfm.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize images with ImageNet mean and std\n",
        "])\n",
        "\n",
        "# Instantiate the training dataset with the specified transform\n",
        "train_dataset = TrainDataset(\n",
        "    root_dir=train_path,  # Path to the training data\n",
        "    images_per_place=img_per_place,  # Number of images per place to use\n",
        "    minimum_images_per_place=min_img_per_place,  # Minimum number of images per place required\n",
        "    transform=train_transform  # Apply the data augmentation/transformations\n",
        ")\n",
        "\n",
        "# Instantiate the validation and test datasets without transformations\n",
        "val_dataset = TestDataset(root_dir=val_path)  # Path to the validation data\n",
        "test_dataset = TestDataset(root_dir=test_path)  # Path to the test data\n",
        "\n",
        "# Create DataLoader for training, validation, and testing\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,  # Use the training dataset\n",
        "    batch_size=batch_size,  # Number of samples per batch\n",
        "    num_workers=2,  # Number of subprocesses for data loading\n",
        "    shuffle=True  # Shuffle the data at every epoch\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,  # Use the validation dataset\n",
        "    batch_size=batch_size,  # Number of samples per batch\n",
        "    num_workers=2,  # Number of subprocesses for data loading\n",
        "    shuffle=False  # Do not shuffle validation data\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,  # Use the test dataset\n",
        "    batch_size=batch_size,  # Number of samples per batch\n",
        "    num_workers=2,  # Number of subprocesses for data loading\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Instantiate the Visual Place Recognition (VPR) model\n",
        "model = VPRModel(\n",
        "    agg_arch=aggregation_method,  # Aggregation method passed as a variable\n",
        "    agg_config={'in_channels': 256,  # Configuration for the selected aggregator\n",
        "                'in_h': 14,\n",
        "                'in_w': 14,\n",
        "                'out_channels': 256,\n",
        "                'mix_depth': 4,\n",
        "                'mlp_ratio': 1,\n",
        "                'out_rows': 4},\n",
        "\n",
        "    # ---- Datasets -----\n",
        "    val_dataset=val_dataset,  # Pass the validation dataset\n",
        "    test_dataset=test_dataset,  # Pass the test dataset\n",
        "\n",
        "    #-----------------------------------\n",
        "    #---- Training hyperparameters -----\n",
        "    lr=0.0002,  # Learning rate (e.g., 0.03 for SGD)\n",
        "    optimizer=optimizer,  # Optimizer type (e.g., SGD, Adam, or AdamW)\n",
        "    weight_decay=weight_decay,  # Weight decay (e.g., 0.001 for SGD or 0.0 for Adam)\n",
        "    momentum=0.9,  # Momentum factor for SGD\n",
        "    milestones=[5, 10, 15, 25],  # Milestones for learning rate scheduler\n",
        "    T_max=T_max,  # Maximum number of iterations for Cosine Annealing LR\n",
        "    lr_mult=0.3,  # Learning rate multiplier for scheduler\n",
        "\n",
        "    #---------------------------------\n",
        "    #---- Training loss function -----\n",
        "    loss_name=loss,  # Loss function (e.g., ContrastiveLoss, TripletMarginLoss)\n",
        "    miner_name=miner,  # Miner for online mining (e.g., PairMarginMiner, MultiSimilarityMiner)\n",
        "    miner_margin=0.1,  # Margin parameter for the miner\n",
        "    faiss_gpu=False,  # Use FAISS with GPU acceleration (False by default)\n",
        "    num_preds_to_save=5  # Number of predictions to save during evaluation\n",
        ")\n",
        "\n",
        "# Create directories for logging and checkpoints with a meaningful name\n",
        "final_epoch = 5  # Set the number of final epochs\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # Generate a timestamp for directory names\n",
        "log_dir = f\"logs/{aggregation_method}_{loss}_{optimizer}_{miner}_weight_decay{weight_decay}/final_epoch{final_epoch}_{timestamp}\"\n",
        "checkpoint_dir = f\"checkpoints/{aggregation_method}_{loss}_{optimizer}_{miner}_weight_decay{weight_decay}/final_epoch{final_epoch}_{timestamp}\"\n",
        "\n",
        "# Setup model checkpointing using PyTorch Lightning\n",
        "# Save the best models according to Recall@1 on the validation set\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    dirpath=checkpoint_dir,  # Directory to save checkpoints\n",
        "    monitor='val/R@1',  # Metric to monitor for saving the best model\n",
        "    filename='epoch({epoch:02d})_step({step:04d})_R1[{val/R@1:.4f}]_R5[{val/R@5:.4f}]',  # Checkpoint filename format\n",
        "    auto_insert_metric_name=False,  # Prevent automatic insertion of metric name into the filename\n",
        "    save_weights_only=True,  # Save only the model weights (not the entire model)\n",
        "    save_top_k=1,  # Save only the best model (top-1)\n",
        "    save_last=True,  # Save the last model checkpoint\n",
        "    mode='max'  # Maximize the monitored metric (Recall@1)\n",
        ")\n",
        "\n",
        "# Instantiate a PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='gpu', devices=[0],  # Use GPU acceleration on device 0\n",
        "    default_root_dir=log_dir,  # Set the root directory for logs\n",
        "    num_sanity_val_steps=0,  # Number of sanity validation steps before training starts\n",
        "    precision=16,  # Use 16-bit precision to reduce memory usage and increase speed\n",
        "    max_epochs=5,  # Maximum number of training epochs\n",
        "    check_val_every_n_epoch=1,  # Run validation every epoch\n",
        "    callbacks=[checkpoint_cb],  # Add checkpointing callback (additional callbacks can be added)\n",
        "    reload_dataloaders_every_n_epochs=1,  # Reload dataloaders to shuffle data every epoch\n",
        "    log_every_n_steps=20,  # Log metrics every 20 steps\n",
        "    # fast_dev_run=True  # Uncomment for a quick development run (skips full training)\n",
        ")\n",
        "\n",
        "# Start training the model\n",
        "# Validate the model before training (optional)\n",
        "# trainer.validate(model=model, dataloaders=val_loader)  # Uncomment if you want to validate before training\n",
        "\n",
        "# Fit the model on the training data and validate it on the validation data\n",
        "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
        "\n",
        "# Test the model after training (optional)\n",
        "# trainer.test(model=model, dataloaders=test_loader)  # Uncomment to run testing after training\n"
      ],
      "metadata": {
        "id": "i6zEfOoCW6R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set global Git configuration for the user email and name\n",
        "!git config --global user.email \"fabio.bertone1@gmail.com\"  # Set your email for Git commits\n",
        "!git config --global user.name \"Bertone-Fabio\"  # Set your Git username\n",
        "\n",
        "# Pull the latest changes from the remote repository to ensure your local repo is up to date\n",
        "!git pull\n",
        "\n",
        "# Add all changes in the working directory to the staging area\n",
        "!git add -A\n",
        "\n",
        "# Commit the changes with a message that includes the checkpoint directory\n",
        "!git commit -m f\"add {checkpoint_dir}\"\n",
        "\n",
        "# Personal Access Token (PAT) for GitHub authentication\n",
        "token = \"\"  # Insert your GitHub PAT here (avoid hardcoding tokens directly in the code)\n",
        "\n",
        "# Configure the remote URL to include the token for authentication\n",
        "repo_url = f\"https://{token}@github.com/Bertone-Fabio/mldl2024.git\"\n",
        "\n",
        "# Set the remote URL for the repository to use the new token-authenticated URL\n",
        "!git remote set-url origin {repo_url}\n",
        "\n",
        "# Push the committed changes to the 'main' branch of the remote repository\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "vY5UatRjYBm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and preprocessing pipeline for training\n",
        "train_transform = tfm.Compose([\n",
        "    tfm.RandAugment(num_ops=3),  # Apply RandAugment with 3 operations for data augmentation\n",
        "    tfm.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    tfm.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize using ImageNet mean and std\n",
        "])\n",
        "\n",
        "# Initialize the training dataset with transformations\n",
        "train_dataset = TrainDataset(\n",
        "    root_dir=train_path,  # Path to the training data directory\n",
        "    images_per_place=img_per_place,  # Number of images per place\n",
        "    minimum_images_per_place=min_img_per_place,  # Minimum images per place required to include in the dataset\n",
        "    transform=train_transform  # Apply the defined transformations\n",
        ")\n",
        "\n",
        "# Initialize the validation and test datasets without transformations\n",
        "val_dataset = TestDataset(root_dir=val_path)  # Path to the validation data directory\n",
        "test_dataset = TestDataset(root_dir=test_path)  # Path to the test data directory\n",
        "\n",
        "# Create DataLoaders for training, validation, and testing\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,  # Training dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=True  # Shuffle the training data each epoch\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,  # Validation dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=False  # Do not shuffle validation data\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,  # Test dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Set the checkpoint path (update this path before every run)\n",
        "checkpoint_path = '/content/mldl2024/checkpoints/MixVPR_MultiSimilarityLoss_adamw_MultiSimilarityMiner_Cosine_annealing_T_max5/final_epoch5_20240709-163808/last.ckpt'\n",
        "\n",
        "# Load the model from the specified checkpoint\n",
        "model = VPRModel.load_from_checkpoint(checkpoint_path)\n",
        "\n",
        "# Create directories for logging and checkpoints using a meaningful name\n",
        "final_epoch = 10  # Define the final epoch number\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # Generate a timestamp for unique directory names\n",
        "log_dir = f\"logs/{aggregation_method}_{loss}_{optimizer}_{miner}_Cosine_annealing_T_max{T_max}/final_epoch{final_epoch}_{timestamp}\"\n",
        "checkpoint_dir = f\"checkpoints/{aggregation_method}_{loss}_{optimizer}_{miner}_Cosine_annealing_T_max{T_max}/final_epoch{final_epoch}_{timestamp}\"\n",
        "\n",
        "# Setup model checkpointing using PyTorch Lightning\n",
        "# Save the best models according to Recall@1 on the validation set\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    dirpath=checkpoint_dir,  # Directory to save checkpoints\n",
        "    monitor='val/R@1',  # Metric to monitor for saving the best model\n",
        "    filename='epoch({epoch:02d})_step({step:04d})_R1[{val/R@1:.4f}]_R5[{val/R@5:.4f}]',  # Checkpoint filename format\n",
        "    auto_insert_metric_name=False,  # Prevent automatic insertion of metric name into the filename\n",
        "    save_weights_only=True,  # Save only the model weights (not the entire model)\n",
        "    save_top_k=1,  # Save only the best model (top-1)\n",
        "    save_last=True,  # Save the last model checkpoint\n",
        "    mode='max',  # Maximize the monitored metric (Recall@1)\n",
        ")\n",
        "\n",
        "# Instantiate the PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='gpu', devices=[0],  # Use GPU acceleration on device 0\n",
        "    default_root_dir=log_dir,  # Set the root directory for logs\n",
        "    num_sanity_val_steps=0,  # Number of sanity validation steps before training starts\n",
        "    precision=16,  # Use 16-bit precision to reduce memory usage and increase speed\n",
        "    max_epochs=5,  # Maximum number of training epochs\n",
        "    check_val_every_n_epoch=1,  # Run validation every epoch\n",
        "    callbacks=[checkpoint_cb],  # Add checkpointing callback (additional callbacks can be added)\n",
        "    reload_dataloaders_every_n_epochs=1,  # Reload dataloaders to shuffle data every epoch\n",
        "    log_every_n_steps=20,  # Log metrics every 20 steps\n",
        "    # fast_dev_run=True  # Uncomment for a quick development run (skips full training)\n",
        ")\n",
        "\n",
        "# Optionally, validate the model before training (e.g., if loading from a checkpoint)\n",
        "# trainer.validate(model=model, dataloaders=val_loader)  # Uncomment to run validation before training\n",
        "\n",
        "# Train the model on the training data and validate on the validation data\n",
        "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
        "\n",
        "# Optionally, test the model after training using the test data\n",
        "# trainer.test(model=model, dataloaders=test_loader, ckpt_path='best')  # Uncomment to run testing after training\n"
      ],
      "metadata": {
        "id": "aF7m8e8JYFWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on San Francisco"
      ],
      "metadata": {
        "id": "2K61Ij6waKUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset parameters\n",
        "train_path = \"/content/data/gsv_xs/train\"  # Path to the training dataset\n",
        "img_per_place = 4  # Number of images per place to be used in training\n",
        "min_img_per_place = 4  # Minimum number of images per place required to include in the dataset\n",
        "val_path = \"/content/data/sf_xs/val\"  # Path to the validation dataset\n",
        "test_path = \"/content/data/tokyo_xs/test\"  # Path to the test dataset\n",
        "batch_size = 64  # Number of samples per batch for training and evaluation\n",
        "\n",
        "# Define the data augmentation and preprocessing pipeline for the training data\n",
        "train_transform = tfm.Compose([\n",
        "    tfm.RandAugment(num_ops=3),  # Apply RandAugment with 3 operations for data augmentation\n",
        "    tfm.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    tfm.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize using ImageNet mean and std\n",
        "])\n",
        "\n",
        "# Initialize the training dataset with transformations\n",
        "train_dataset = TrainDataset(\n",
        "    root_dir=train_path,  # Path to the training data directory\n",
        "    images_per_place=img_per_place,  # Number of images per place\n",
        "    minimum_images_per_place=min_img_per_place,  # Minimum images per place required to include in the dataset\n",
        "    transform=train_transform  # Apply the defined transformations\n",
        ")\n",
        "\n",
        "# Initialize the validation and test datasets without transformations\n",
        "val_dataset = TestDataset(root_dir=val_path)  # Path to the validation data directory\n",
        "test_dataset = TestDataset(root_dir=test_path)  # Path to the test data directory\n",
        "\n",
        "# Create DataLoaders for training, validation, and testing\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,  # Training dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=True  # Shuffle the training data each epoch\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,  # Validation dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=False  # Do not shuffle validation data\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,  # Test dataset\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    num_workers=2,  # Number of workers for data loading\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Set the checkpoint path (update this path before every run)\n",
        "checkpoint_path = '/content/mldl2024/checkpoints/gem_MultiSimilarityLoss_adam_None/final_epoch10_20240531-120547/last.ckpt'\n",
        "\n",
        "# Load the model from the specified checkpoint\n",
        "model = VPRModel.load_from_checkpoint(checkpoint_path)\n",
        "\n",
        "# Set the test dataset in the model to the newly loaded test dataset\n",
        "model.change_test_dataset(test_dataset)\n",
        "\n",
        "# Create directories for logging and checkpoints using a meaningful name\n",
        "final_epoch = 10  # Define the final epoch number\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # Generate a timestamp for unique directory names\n",
        "\n",
        "# Extract the directory name from the checkpoint path\n",
        "checkpoint_dir_name = os.path.basename(os.path.dirname(checkpoint_path))\n",
        "\n",
        "# Create directories for logs and checkpoints based on the checkpoint name and timestamp\n",
        "log_dir = f\"logs/{checkpoint_dir_name}/test_{timestamp}\"\n",
        "checkpoint_dir = f\"checkpoints/{checkpoint_dir_name}/test_{timestamp}\"\n",
        "\n",
        "# Setup model checkpointing using PyTorch Lightning\n",
        "# Save the best models according to Recall@1 on the validation set\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    dirpath=checkpoint_dir,  # Directory to save checkpoints\n",
        "    monitor='val/R@1',  # Metric to monitor for saving the best model\n",
        "    filename='epoch({epoch:02d})_step({step:04d})_R1[{val/R@1:.4f}]_R5[{val/R@5:.4f}]',  # Checkpoint filename format\n",
        "    auto_insert_metric_name=False,  # Prevent automatic insertion of metric name into the filename\n",
        "    save_weights_only=True,  # Save only the model weights (not the entire model)\n",
        "    save_top_k=1,  # Save only the best model (top-1)\n",
        "    save_last=True,  # Save the last model checkpoint\n",
        "    mode='max',  # Maximize the monitored metric (Recall@1)\n",
        ")\n",
        "\n",
        "# Instantiate the PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='gpu', devices=[0],  # Use GPU acceleration on device 0\n",
        "    default_root_dir=log_dir,  # Set the root directory for logs\n",
        "    num_sanity_val_steps=0,  # Number of sanity validation steps before training starts\n",
        "    precision=16,  # Use 16-bit precision to reduce memory usage and increase speed\n",
        "    max_epochs=5,  # Maximum number of training epochs\n",
        "    check_val_every_n_epoch=1,  # Run validation every epoch\n",
        "    callbacks=[checkpoint_cb],  # Add checkpointing callback (additional callbacks can be added)\n",
        "    reload_dataloaders_every_n_epochs=1,  # Reload dataloaders to shuffle data every epoch\n",
        "    log_every_n_steps=20,  # Log metrics every 20 steps\n",
        "    # fast_dev_run=True  # Uncomment for a quick development run (skips full training)\n",
        ")\n",
        "\n",
        "# If the model's current epoch is 0, set the final epoch to 15\n",
        "if model.current_epoch == 0:\n",
        "    final_epoch = 15\n",
        "\n",
        "# Validate the model on the validation dataset\n",
        "trainer.validate(model=model, dataloaders=val_loader)\n",
        "\n",
        "# Test the model on the test dataset\n",
        "trainer.test(model=model, dataloaders=test_loader)\n"
      ],
      "metadata": {
        "id": "WbhOYKW4Yuoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on Tokyo"
      ],
      "metadata": {
        "id": "99sUbGkkaiCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the test dataset\n",
        "test_path = \"/content/data/tokyo_xs/test\"\n",
        "\n",
        "# Set the test dataset in the model\n",
        "# This updates the model's internal state to use the specified test dataset\n",
        "model.change_test_dataset(test_dataset)\n",
        "\n",
        "# Define the final epoch number and generate a timestamp for directory naming\n",
        "final_epoch = 10  # Define the final epoch number for naming directories\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")  # Generate a timestamp for unique directory names\n",
        "\n",
        "# Extract the directory name from the checkpoint path\n",
        "checkpoint_dir_name = os.path.basename(os.path.dirname(checkpoint_path))\n",
        "\n",
        "# Create directories for logs and checkpoints based on the checkpoint name and timestamp\n",
        "log_dir = f\"logs/{checkpoint_dir_name}/test_{timestamp}\"  # Directory for logs\n",
        "checkpoint_dir = f\"checkpoints/{checkpoint_dir_name}/test_{timestamp}\"  # Directory for checkpoints\n",
        "\n",
        "# Set up model checkpointing using PyTorch Lightning\n",
        "# The model checkpoints will be saved based on the best Recall@1 score on the validation set\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    dirpath=checkpoint_dir,  # Directory to save checkpoints\n",
        "    monitor='val/R@1',  # Metric to monitor for saving the best model\n",
        "    filename='epoch({epoch:02d})_step({step:04d})_R1[{val/R@1:.4f}]_R5[{val/R@5:.4f}]',  # Checkpoint filename format\n",
        "    auto_insert_metric_name=False,  # Prevent automatic insertion of metric name into the filename\n",
        "    save_weights_only=True,  # Save only the model weights (not the entire model)\n",
        "    save_top_k=1,  # Save only the best model (top-1)\n",
        "    save_last=True,  # Save the last model checkpoint\n",
        "    mode='max',  # Maximize the monitored metric (Recall@1)\n",
        ")\n",
        "\n",
        "# Instantiate the PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='gpu', devices=[0],  # Use GPU acceleration on device 0\n",
        "    default_root_dir=log_dir,  # Set the root directory for logs\n",
        "    num_sanity_val_steps=0,  # Number of sanity validation steps before training starts\n",
        "    precision=16,  # Use 16-bit precision to reduce memory usage and increase speed\n",
        "    max_epochs=5,  # Maximum number of training epochs\n",
        "    check_val_every_n_epoch=1,  # Run validation every epoch\n",
        "    callbacks=[checkpoint_cb],  # Add checkpointing callback (additional callbacks can be added)\n",
        "    reload_dataloaders_every_n_epochs=1,  # Reload dataloaders to shuffle data every epoch\n",
        "    log_every_n_steps=20,  # Log metrics every 20 steps\n",
        "    # fast_dev_run=True  # Uncomment for a quick development run (skips full training)\n",
        ")\n",
        "\n",
        "# Adjust final epoch if the model is at the beginning of training\n",
        "if model.current_epoch == 0:\n",
        "    final_epoch = 15\n",
        "\n",
        "# Validate the model on the validation dataset\n",
        "trainer.validate(model=model, dataloaders=val_loader)\n",
        "\n",
        "# Test the model on the test dataset\n",
        "trainer.test(model=model, dataloaders=test_loader)\n"
      ],
      "metadata": {
        "id": "L5yzh41jaPFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image visualization"
      ],
      "metadata": {
        "id": "SnyAXm6bbash"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_images(folder_path, images_per_block):\n",
        "    \"\"\"\n",
        "    Visualizes images from a given folder and its subfolders in blocks of a specified number.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): The path to the folder containing the images.\n",
        "        images_per_block (int): The number of images to display in each block.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get a list of all image paths in the folder and its subfolders\n",
        "    image_paths = []\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_path = os.path.join(root, file)\n",
        "                image_paths.append(image_path)\n",
        "\n",
        "    # Sort the image paths alphabetically\n",
        "    image_paths.sort()\n",
        "\n",
        "    # Visualize images in blocks\n",
        "    num_blocks = len(image_paths) // images_per_block\n",
        "    if len(image_paths) % images_per_block != 0:\n",
        "        num_blocks += 1\n",
        "\n",
        "    for block_index in range(num_blocks):\n",
        "        start_index = block_index * images_per_block\n",
        "        end_index = min(start_index + images_per_block, len(image_paths))\n",
        "\n",
        "        block_images = []\n",
        "        for image_index in range(start_index, end_index):\n",
        "            image_path = image_paths[image_index]\n",
        "            image = plt.imread(image_path)\n",
        "            block_images.append(image)\n",
        "\n",
        "        # Display images in the block\n",
        "        fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15, 15))\n",
        "        for row_index in range(4):\n",
        "            for col_index in range(5):\n",
        "                image_index = row_index * 5 + col_index\n",
        "                if image_index < len(block_images):\n",
        "                    axes[row_index, col_index].imshow(block_images[image_index])\n",
        "                    axes[row_index, col_index].axis('off')\n",
        "                else:\n",
        "                    axes[row_index, col_index].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example usage\n",
        "image_folder = \"/content/mldl2024/images/avgpool_MultiSimilarityLoss_adam_None/epoch10/test/tokyo_xs\"  # Replace with your folder path\n",
        "images_per_block = 20\n",
        "\n",
        "visualize_images(image_folder, images_per_block)"
      ],
      "metadata": {
        "id": "8j5LfpTgbcWR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}